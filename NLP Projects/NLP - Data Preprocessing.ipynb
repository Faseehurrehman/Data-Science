{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f701b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695b0124",
   "metadata": {},
   "source": [
    "## 1 - Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5908af68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3].lower() # lowercasing 3rd row of review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39625a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. <br /><br />the...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534aea91",
   "metadata": {},
   "source": [
    "## 2 - Remove HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1beaf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # regular expression\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08bcf908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. the filming tec...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(remove_html_tags)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7353c6b0",
   "metadata": {},
   "source": [
    "## 3 - Remove URLs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62d4153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Check out my notebook www.google.com https://www.kaggle.com/tutor/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eafc5da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'',text)\n",
    "    \n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eb5f6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check out my notebook  '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c376fc3",
   "metadata": {},
   "source": [
    "## 4 - Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c75bc9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import time\n",
    "print(string.punctuation)\n",
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12d302bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method takes more time if we have large data. So this method is only good for small data.\n",
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed76cdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Youarenotgood\n"
     ]
    }
   ],
   "source": [
    "text = 'You,are.not;good:'\n",
    "print(remove_punc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5d084ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        one of the other reviewers has mentioned that ...\n",
      "1        a wonderful little production the filming tech...\n",
      "2        i thought this was a wonderful way to spend ti...\n",
      "3        basically theres a family where a little boy j...\n",
      "4        petter matteis love in the time of money is a ...\n",
      "                               ...                        \n",
      "49995    i thought this movie did a down right good job...\n",
      "49996    bad plot bad dialogue bad acting idiotic direc...\n",
      "49997    i am a catholic taught in parochial elementary...\n",
      "49998    im going to have to disagree with the previous...\n",
      "49999    no one expects the star trek movies to be high...\n",
      "Name: review, Length: 50000, dtype: object\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(df['review'].apply(remove_punc))\n",
    "start = time.time()\n",
    "time1 = time.time() - start\n",
    "print(time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65612976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method is good for large data.\n",
    "def remove_punc1(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8a924f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        one of the other reviewers has mentioned that ...\n",
      "1        a wonderful little production the filming tech...\n",
      "2        i thought this was a wonderful way to spend ti...\n",
      "3        basically theres a family where a little boy j...\n",
      "4        petter matteis love in the time of money is a ...\n",
      "                               ...                        \n",
      "49995    i thought this movie did a down right good job...\n",
      "49996    bad plot bad dialogue bad acting idiotic direc...\n",
      "49997    i am a catholic taught in parochial elementary...\n",
      "49998    im going to have to disagree with the previous...\n",
      "49999    no one expects the star trek movies to be high...\n",
      "Name: review, Length: 50000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['review'].apply(remove_punc1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97da127e",
   "metadata": {},
   "source": [
    "## 5 -  Chat Word Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c082bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {'AFAIK':'As Far As I Know',\n",
    "'AFK': 'Away From Keyboard',\n",
    "'ASAP':'As Soon As Possible',\n",
    "'ATK': 'At The Keyboard',\n",
    "'ATM':'At The Moment',\n",
    "'A3': 'Anytime, Anywhere, Anyplace',\n",
    "'BAK':'Back At Keyboard',\n",
    "'BBL':'Be Back Later',\n",
    "'BBS':'Be Back Soon',\n",
    "'BFN':'Bye For Now',\n",
    "'B4N':'Bye For Now',\n",
    "'BRB':'Be Right Back',\n",
    "'BRT':'Be Right There',\n",
    "'BTW':'By The Way',\n",
    "'B4':'Before',\n",
    "'B4N':'Bye For Now',\n",
    "'CU':'See You',\n",
    "'CUL8R':'See You Later',\n",
    "'CYA':'See You',\n",
    "'FAQ':'Frequently Asked Questions',\n",
    "'FC':'Fingers Crossed',\n",
    "'FWIW':'For What It is Worth',\n",
    "'FYI':'For Your Information',\n",
    "'GAL':'Get a Life',\n",
    "'GG':'Good Game',\n",
    "'GN':'Good Night',\n",
    "'GMTA':'Great Minds Think Alike',\n",
    "'GR8':'Great!',\n",
    "'G9':'Genius',\n",
    "'IC':'I See',\n",
    "'ICQ':'I Seek you (also a chat program)',\n",
    "'ILU':'I Love You',\n",
    "'IMHO':'In My Honest/Humble Opinion',\n",
    "'IMO':'In My Opinion',\n",
    "'IOW':'In Other Words',\n",
    "'IRL':'In Real Life',\n",
    "'KISS':'Keep It Simple, Stupid',\n",
    "'LDR':'Long Distance Relationship',\n",
    "'LMAO':'Laugh My A.. Off',\n",
    "'LOL':'Laughing Out Loud',\n",
    "'LTNS':'Long Time No See',\n",
    "'L8R':'Later',\n",
    "'MTE':'My Thoughts Exactly',\n",
    "'M8':'Mate',\n",
    "'NRN':'No Reply Necessary',\n",
    "'OIC':'Oh I See',\n",
    "'PITA':'Pain In The A..',\n",
    "'PRT':'Party',\n",
    "'PRW':'Parents Are Watching',\n",
    "'QPSA?':'Que Pasa?',\n",
    "'ROFL':'Rolling On The Floor Laughing',\n",
    "'ROFLOL':'Rolling On The Floor Laughing Out Loud',\n",
    "'ROTFLMAO':'Rolling On The Floor Laughing My A.. Off',\n",
    "'SK8':'Skate',\n",
    "'STATS':'Your sex and age',\n",
    "'ASL':'Age, Sex, Location',\n",
    "'THX':'Thank You',\n",
    "'TTFN':'Ta-Ta For Now!',\n",
    "'TTYL':'Talk To You Later',\n",
    "'U':'You',\n",
    "'U2':'You Too',\n",
    "'U4E':'Yours For Ever',\n",
    "'WB':'Welcome Back',\n",
    "'WTF':'What The F...',\n",
    "'WTG':'Way To Go!',\n",
    "'WUF':'Where Are You From?',\n",
    "'W8':'Wait...',\n",
    "'7K':'Sick:-D Laugher'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d5a381e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFAIK': 'As Far As I Know',\n",
       " 'AFK': 'Away From Keyboard',\n",
       " 'ASAP': 'As Soon As Possible',\n",
       " 'ATK': 'At The Keyboard',\n",
       " 'ATM': 'At The Moment',\n",
       " 'A3': 'Anytime, Anywhere, Anyplace',\n",
       " 'BAK': 'Back At Keyboard',\n",
       " 'BBL': 'Be Back Later',\n",
       " 'BBS': 'Be Back Soon',\n",
       " 'BFN': 'Bye For Now',\n",
       " 'B4N': 'Bye For Now',\n",
       " 'BRB': 'Be Right Back',\n",
       " 'BRT': 'Be Right There',\n",
       " 'BTW': 'By The Way',\n",
       " 'B4': 'Before',\n",
       " 'CU': 'See You',\n",
       " 'CUL8R': 'See You Later',\n",
       " 'CYA': 'See You',\n",
       " 'FAQ': 'Frequently Asked Questions',\n",
       " 'FC': 'Fingers Crossed',\n",
       " 'FWIW': 'For What It is Worth',\n",
       " 'FYI': 'For Your Information',\n",
       " 'GAL': 'Get a Life',\n",
       " 'GG': 'Good Game',\n",
       " 'GN': 'Good Night',\n",
       " 'GMTA': 'Great Minds Think Alike',\n",
       " 'GR8': 'Great!',\n",
       " 'G9': 'Genius',\n",
       " 'IC': 'I See',\n",
       " 'ICQ': 'I Seek you (also a chat program)',\n",
       " 'ILU': 'I Love You',\n",
       " 'IMHO': 'In My Honest/Humble Opinion',\n",
       " 'IMO': 'In My Opinion',\n",
       " 'IOW': 'In Other Words',\n",
       " 'IRL': 'In Real Life',\n",
       " 'KISS': 'Keep It Simple, Stupid',\n",
       " 'LDR': 'Long Distance Relationship',\n",
       " 'LMAO': 'Laugh My A.. Off',\n",
       " 'LOL': 'Laughing Out Loud',\n",
       " 'LTNS': 'Long Time No See',\n",
       " 'L8R': 'Later',\n",
       " 'MTE': 'My Thoughts Exactly',\n",
       " 'M8': 'Mate',\n",
       " 'NRN': 'No Reply Necessary',\n",
       " 'OIC': 'Oh I See',\n",
       " 'PITA': 'Pain In The A..',\n",
       " 'PRT': 'Party',\n",
       " 'PRW': 'Parents Are Watching',\n",
       " 'QPSA?': 'Que Pasa?',\n",
       " 'ROFL': 'Rolling On The Floor Laughing',\n",
       " 'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
       " 'ROTFLMAO': 'Rolling On The Floor Laughing My A.. Off',\n",
       " 'SK8': 'Skate',\n",
       " 'STATS': 'Your sex and age',\n",
       " 'ASL': 'Age, Sex, Location',\n",
       " 'THX': 'Thank You',\n",
       " 'TTFN': 'Ta-Ta For Now!',\n",
       " 'TTYL': 'Talk To You Later',\n",
       " 'U': 'You',\n",
       " 'U2': 'You Too',\n",
       " 'U4E': 'Yours For Ever',\n",
       " 'WB': 'Welcome Back',\n",
       " 'WTF': 'What The F...',\n",
       " 'WTG': 'Way To Go!',\n",
       " 'WUF': 'Where Are You From?',\n",
       " 'W8': 'Wait...',\n",
       " '7K': 'Sick:-D Laugher'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbef709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words:\n",
    "            new_text.append(chat_words[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b87a3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frequently Asked Questions : What you want to do?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion('FAQ : What you want to do?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8976d9b",
   "metadata": {},
   "source": [
    "## 6 - Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b50b90f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65dbc61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Certain conditions are not favorable here'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text = 'Certan condishons are not favorabal here'\n",
    "text = TextBlob(incorrect_text)\n",
    "text.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dbd1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_text(text):\n",
    "    text = TextBlob(text)\n",
    "    text.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "026f1065",
   "metadata": {},
   "outputs": [],
   "source": [
    " # df['review']=df['review'].apply(correct_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246b72da",
   "metadata": {},
   "source": [
    "## 7 - Removing Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0670f5",
   "metadata": {},
   "source": [
    "<b>The Words which help in only sentence formation but not in sentence meaning. <br>\n",
    "    Examples: a, the, of, are, is, my, etc. <br>\n",
    "    In Parts of Speech tagging, we don't remove stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1608cbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c8df733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5706793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split(): # breaking text into words\n",
    "        if word in stopwords.words('english'): # Checking whether word is in English language\n",
    "            new_text.append(' ') # Then we will replace empty in new_text in the place of that word\n",
    "        else:\n",
    "            new_text.append(word) # if that is not stopword, then add word in new_text list \n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dad4a02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probably     issues   resolved'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords('probably my all issues are resolved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfe88749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['review'] = df['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a314463",
   "metadata": {},
   "source": [
    "## 7 - Handling Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73edd756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emotion\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols and pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport and map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (ios)\n",
    "                               u\"\\U00002702-\\U00002780\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\",flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38eec551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are smily.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emojis(\"You are smily.ðŸ˜ƒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "464f612b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is :grinning_face_with_big_eyes:\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.demojize('Python is ðŸ˜ƒ'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5fef4c",
   "metadata": {},
   "source": [
    "## 8 - Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9722d6d2",
   "metadata": {},
   "source": [
    "<b> Breaking text into smaller parts (tokens). Smaller parts can be words, sentences, phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38325227",
   "metadata": {},
   "source": [
    "### i - Using Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d357e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'Lahore']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word Tokenization\n",
    "sent1 = 'I am going to Lahore'\n",
    "sent1.split() # Splitting on the basis of spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4fc1eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to Lahore', ' You are going to Karachi']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence Tokenization\n",
    "sent2 = 'I am going to Lahore. You are going to Karachi'\n",
    "sent2.split('.') # Splitting on the basis of full stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62d47a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You', 'are', 'very', 'good!']\n",
      "['I', 'am', 'good', 'person']\n"
     ]
    }
   ],
   "source": [
    "# Problem Faced by Split Function\n",
    "sent3 = 'You are very good!'\n",
    "print(sent3.split())\n",
    "\n",
    "sent4 = 'I am good person'\n",
    "print(sent4.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203976af",
   "metadata": {},
   "source": [
    "<b> The above result shows that good and good! are two different words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa0179d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I live in Lahore', 'You live in Islamabad', ' What do u do? I am farmer']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"I live in Lahore.You live in Islamabad. What do u do? I am farmer\"\n",
    "sent.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05b489e",
   "metadata": {},
   "source": [
    "<b> The above result shows that sentences have not been tokenized by '?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da011d08",
   "metadata": {},
   "source": [
    "### ii-Using Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "985c76da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'Delhi']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent = 'I am going to Delhi!'\n",
    "tokens = re.findall(\"[\\w']+\", sent)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "542f05f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am good',\n",
       " 'You are not good! Where do u live',\n",
       " ' I live in Lahore: I eat a lot of vegetables',\n",
       " ' You eat some']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting on the basis of your choice\n",
    "text1 = 'I am good.You are not good! Where do u live? I live in Lahore: I eat a lot of vegetables; You eat some' \n",
    "sentences = re.compile('[.?;]').split(text1)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574288de",
   "metadata": {},
   "source": [
    "### iii-Using NLTK Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6cd2a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not perfect 100% result. But better results\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47d3807d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You are good.',\n",
       " 'I am also good.',\n",
       " 'Where do u live?',\n",
       " 'I live in Lahore: I live in Karachi; But you live in Islamabad.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'You are good. I am also good. Where do u live? I live in Lahore: I live in Karachi; But you live in Islamabad.'\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04ad26d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'a', 'Ph.D', 'in', 'A.i']\n",
      "['We', \"'re\", 'here', 'to', 'help', '!', 'Mail', 'us', 'at', '123', '@', 'gmail.com']\n",
      "['A', '5km', 'ride', 'cost', '$', '20.5']\n"
     ]
    }
   ],
   "source": [
    "text1 = 'I have a Ph.D in A.i'\n",
    "text2 = \"We're here to help! Mail us at 123@gmail.com\"\n",
    "text3 = 'A 5km ride cost $20.5'\n",
    "print(word_tokenize(text1))\n",
    "print(word_tokenize(text2))\n",
    "print(word_tokenize(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e3ec81",
   "metadata": {},
   "source": [
    "### iv-Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6dfc36a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (2.4.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (1.9.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (1.22.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (8.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (63.4.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (1.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (3.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\admin\\anaconda3\\envs\\a\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#Better than NLTK Library\n",
    "!pip install spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "424e08c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb11c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting sentences into documents\n",
    "doc1=nlp(text1)\n",
    "doc2=nlp(text2)\n",
    "doc3=nlp(text3)\n",
    "doc4=nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b799f676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "5\n",
      "km\n",
      "ride\n",
      "cost\n",
      "$\n",
      "20.5\n"
     ]
    }
   ],
   "source": [
    "for token in doc3:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa5eac44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You\n",
      "are\n",
      "good\n",
      ".\n",
      "I\n",
      "am\n",
      "also\n",
      "good\n",
      ".\n",
      "Where\n",
      "do\n",
      "u\n",
      "live\n",
      "?\n",
      "I\n",
      "live\n",
      "in\n",
      "Lahore\n",
      ":\n",
      "I\n",
      "live\n",
      "in\n",
      "Karachi\n",
      ";\n",
      "But\n",
      "you\n",
      "live\n",
      "in\n",
      "Islamabad\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc4:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f04b0d5",
   "metadata": {},
   "source": [
    "## 9 - Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc387ba3",
   "metadata": {},
   "source": [
    "<b> To retrieve root word. Mostly used in Information Retrieval Systems.Multiple stemmers are used.<br>\n",
    "    i - Porter Stemmer - For English Language<br>\n",
    "    ii - snowball stemmer - For Other Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55320b15",
   "metadata": {},
   "source": [
    "### i - Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8f4d74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When to show user output, then lemmatization is better. Output of Lemmatization will always be English language word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77deb04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26007841",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    return \" \" .join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0418446a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk is good, he ha walked, walk and walk'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'Walking is good, He has walked, walk and walks'\n",
    "stem_words(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "01dee161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['review'].apply(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c88e9ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smoke is danger probabl due to it start univers time'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = 'Smoking is dangerous probably due to its starting university time'\n",
    "stem_words(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff099ce0",
   "metadata": {},
   "source": [
    "## 10 - Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c2ac85",
   "metadata": {},
   "source": [
    "<b> We use WordNet Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a265bc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "Smoking             Smoking             \n",
      "is                  is                  \n",
      "dangerous           dangerous           \n",
      "probably            probably            \n",
      "due                 due                 \n",
      "to                  to                  \n",
      "its                 it                  \n",
      "starting            starting            \n",
      "university          university          \n",
      "time                time                \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentence = 'Smoking is dangerous probably due to its starting university time'\n",
    "punctuations = \"?:!.,;\"\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print(\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36156eb",
   "metadata": {},
   "source": [
    "<b>Difference Between Stemming and Lemmatization<br>\n",
    "Both work same - to retrive root word. <br>\n",
    " When to show user output, then lemmatization is suitable. Because output of Stemming is sometimes is not English Language word (e.g. Probabl). Output of Lemmatization will always be English language word.<br>\n",
    "Lemmatization is slower than Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e99ea4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "486da009",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://api.themoviedb.org/3/movie/top_rated?api_key=8265bd1679663a7ea12ac168da84d2e8&language=en-US&page=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb3a1d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'adult': False,\n",
       "  'backdrop_path': '/rSPw7tgCH9c6NqICZef4kZjFOQ5.jpg',\n",
       "  'genre_ids': [18, 80],\n",
       "  'id': 238,\n",
       "  'original_language': 'en',\n",
       "  'original_title': 'The Godfather',\n",
       "  'overview': 'Spanning the years 1945 to 1955, a chronicle of the fictional Italian-American Corleone crime family. When organized crime family patriarch, Vito Corleone barely survives an attempt on his life, his youngest son, Michael steps in to take care of the would-be killers, launching a campaign of bloody revenge.',\n",
       "  'popularity': 92.658,\n",
       "  'poster_path': '/3bhkrj58Vtu7enYsRolD1fZdja1.jpg',\n",
       "  'release_date': '1972-03-14',\n",
       "  'title': 'The Godfather',\n",
       "  'video': False,\n",
       "  'vote_average': 8.7,\n",
       "  'vote_count': 16739},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/kXfqcdQKsToO0OUXHcrrNCHDBzO.jpg',\n",
       "  'genre_ids': [18, 80],\n",
       "  'id': 278,\n",
       "  'original_language': 'en',\n",
       "  'original_title': 'The Shawshank Redemption',\n",
       "  'overview': 'Framed in the 1940s for the double murder of his wife and her lover, upstanding banker Andy Dufresne begins a new life at the Shawshank prison, where he puts his accounting skills to work for an amoral warden. During his long stretch in prison, Dufresne comes to be admired by the other inmates -- including an older prisoner named Red -- for his integrity and unquenchable sense of hope.',\n",
       "  'popularity': 70.245,\n",
       "  'poster_path': '/q6y0Go1tsGEsmtFryDOJo3dEmqu.jpg',\n",
       "  'release_date': '1994-09-23',\n",
       "  'title': 'The Shawshank Redemption',\n",
       "  'video': False,\n",
       "  'vote_average': 8.7,\n",
       "  'vote_count': 22458},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/kGzFbGhp99zva6oZODW5atUtnqi.jpg',\n",
       "  'genre_ids': [18, 80],\n",
       "  'id': 240,\n",
       "  'original_language': 'en',\n",
       "  'original_title': 'The Godfather Part II',\n",
       "  'overview': 'In the continuing saga of the Corleone crime family, a young Vito Corleone grows up in Sicily and in 1910s New York. In the 1950s, Michael Corleone attempts to expand the family business into Las Vegas, Hollywood and Cuba.',\n",
       "  'popularity': 58.823,\n",
       "  'poster_path': '/hek3koDUyRQk7FIhPXsa6mT2Zc3.jpg',\n",
       "  'release_date': '1974-12-20',\n",
       "  'title': 'The Godfather Part II',\n",
       "  'video': False,\n",
       "  'vote_average': 8.6,\n",
       "  'vote_count': 10137},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/zb6fM1CX41D9rF9hdgclu0peUmy.jpg',\n",
       "  'genre_ids': [18, 36, 10752],\n",
       "  'id': 424,\n",
       "  'original_language': 'en',\n",
       "  'original_title': \"Schindler's List\",\n",
       "  'overview': 'The true story of how businessman Oskar Schindler saved over a thousand Jewish lives from the Nazis while they worked as slaves in his factory during World War II.',\n",
       "  'popularity': 49.815,\n",
       "  'poster_path': '/sF1U4EUQS8YHUYjNl3pMGNIQyr0.jpg',\n",
       "  'release_date': '1993-12-15',\n",
       "  'title': \"Schindler's List\",\n",
       "  'video': False,\n",
       "  'vote_average': 8.6,\n",
       "  'vote_count': 13319},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/vI3aUGTuRRdM7J78KIdW98LdxE5.jpg',\n",
       "  'genre_ids': [35, 18, 10749],\n",
       "  'id': 19404,\n",
       "  'original_language': 'hi',\n",
       "  'original_title': 'à¤¦à¤¿à¤²à¤µà¤¾à¤²à¥‡ à¤¦à¥à¤²à¥à¤¹à¤¨à¤¿à¤¯à¤¾ à¤²à¥‡ à¤œà¤¾à¤¯à¥‡à¤‚à¤—à¥‡',\n",
       "  'overview': 'Raj is a rich, carefree, happy-go-lucky second generation NRI. Simran is the daughter of Chaudhary Baldev Singh, who in spite of being an NRI is very strict about adherence to Indian values. Simran has left for India to be married to her childhood fiancÃ©. Raj leaves for India with a mission at his hands, to claim his lady love under the noses of her whole family. Thus begins a saga.',\n",
       "  'popularity': 21.861,\n",
       "  'poster_path': '/2CAL2433ZeIihfX1Hb2139CX0pW.jpg',\n",
       "  'release_date': '1995-10-19',\n",
       "  'title': 'Dilwale Dulhania Le Jayenge',\n",
       "  'video': False,\n",
       "  'vote_average': 8.6,\n",
       "  'vote_count': 3909},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/Ab8mkHmkYADjU7wQiOkia9BzGvS.jpg',\n",
       "  'genre_ids': [16, 10751, 14],\n",
       "  'id': 129,\n",
       "  'original_language': 'ja',\n",
       "  'original_title': 'åƒã¨åƒå°‹ã®ç¥žéš ã—',\n",
       "  'overview': 'A young girl, Chihiro, becomes trapped in a strange new world of spirits. When her parents undergo a mysterious transformation, she must call upon the courage she never knew she had to free her family.',\n",
       "  'popularity': 78.766,\n",
       "  'poster_path': '/39wmItIWsg5sZMyRUHLkWBcuVCM.jpg',\n",
       "  'release_date': '2001-07-20',\n",
       "  'title': 'Spirited Away',\n",
       "  'video': False,\n",
       "  'vote_average': 8.5,\n",
       "  'vote_count': 13429},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/bxSBOAD8AuMHYMdW3jso9npAkgt.jpg',\n",
       "  'genre_ids': [10751, 18],\n",
       "  'id': 667257,\n",
       "  'original_language': 'es',\n",
       "  'original_title': 'Cosas imposibles',\n",
       "  'overview': 'Matilde is a woman who, after the death of her husband - a man who constantly abused her - finds her new best friend in Miguel, her young, insecure, disoriented and even dealer neighbor',\n",
       "  'popularity': 10.68,\n",
       "  'poster_path': '/t2Ew8NZ8Ci2kqmoecZUNQUFDJnQ.jpg',\n",
       "  'release_date': '2021-06-17',\n",
       "  'title': 'Impossible Things',\n",
       "  'video': False,\n",
       "  'vote_average': 8.5,\n",
       "  'vote_count': 270},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/mMtUybQ6hL24FXo0F3Z4j2KG7kZ.jpg',\n",
       "  'genre_ids': [10749, 16, 18],\n",
       "  'id': 372058,\n",
       "  'original_language': 'ja',\n",
       "  'original_title': 'å›ã®åã¯ã€‚',\n",
       "  'overview': 'High schoolers Mitsuha and Taki are complete strangers living separate lives. But one night, they suddenly switch places. Mitsuha wakes up in Takiâ€™s body, and he in hers. This bizarre occurrence continues to happen randomly, and the two must adjust their lives around each other.',\n",
       "  'popularity': 133.355,\n",
       "  'poster_path': '/q719jXXEzOoYaps6babgKnONONX.jpg',\n",
       "  'release_date': '2016-08-26',\n",
       "  'title': 'Your Name.',\n",
       "  'video': False,\n",
       "  'vote_average': 8.5,\n",
       "  'vote_count': 9135},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/qqHQsStV6exghCM7zbObuYBiYxw.jpg',\n",
       "  'genre_ids': [18],\n",
       "  'id': 389,\n",
       "  'original_language': 'en',\n",
       "  'original_title': '12 Angry Men',\n",
       "  'overview': \"The defense and the prosecution have rested and the jury is filing into the jury room to decide if a young Spanish-American is guilty or innocent of murdering his father. What begins as an open and shut case soon becomes a mini-drama of each of the jurors' prejudices and preconceptions about the trial, the accused, and each other.\",\n",
       "  'popularity': 29.137,\n",
       "  'poster_path': '/ppd84D2i9W8jXmsyInGyihiSyqz.jpg',\n",
       "  'release_date': '1957-04-10',\n",
       "  'title': '12 Angry Men',\n",
       "  'video': False,\n",
       "  'vote_average': 8.5,\n",
       "  'vote_count': 6725},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/TU9NIjwzjoKPwQHoHshkFcQUCG.jpg',\n",
       "  'genre_ids': [35, 53, 18],\n",
       "  'id': 496243,\n",
       "  'original_language': 'ko',\n",
       "  'original_title': 'ê¸°ìƒì¶©',\n",
       "  'overview': \"All unemployed, Ki-taek's family takes peculiar interest in the wealthy and glamorous Parks for their livelihood until they get entangled in an unexpected incident.\",\n",
       "  'popularity': 59.662,\n",
       "  'poster_path': '/7IiTTgloJzvGI1TAYymCfbfl3vT.jpg',\n",
       "  'release_date': '2019-05-30',\n",
       "  'title': 'Parasite',\n",
       "  'video': False,\n",
       "  'vote_average': 8.5,\n",
       "  'vote_count': 14534},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/jtAI6OJIWLWiRItNSZoWjrsUtmi.jpg',\n",
       "  'genre_ids': [10749],\n",
       "  'id': 724089,\n",
       "  'original_language': 'en',\n",
       "  'original_title': \"Gabriel's Inferno: Part II\",\n",
       "  'overview': \"Professor Gabriel Emerson finally learns the truth about Julia Mitchell's identity, but his realization comes a moment too late. Julia is done waiting for the well-respected Dante specialist to remember her and wants nothing more to do with him. Can Gabriel win back her heart before she finds love in another's arms?\",\n",
       "  'popularity': 11.997,\n",
       "  'poster_path': '/x5o8cLZfEXMoZczTYWLrUo1P7UJ.jpg',\n",
       "  'release_date': '2020-07-31',\n",
       "  'title': \"Gabriel's Inferno: Part II\",\n",
       "  'video': False,\n",
       "  'vote_average': 8.5,\n",
       "  'vote_count': 1439},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/3RMLbSEXOn1CzLoNT7xFeLfdxhq.jpg',\n",
       "  'genre_ids': [10749, 16],\n",
       "  'id': 372754,\n",
       "  'original_language': 'ja',\n",
       "  'original_title': 'åŒç´šç”Ÿ',\n",
       "  'overview': 'Rihito Sajo, an honor student with a perfect score on the entrance exam and Hikaru Kusakabe, in a band and popular among girls, would have never crossed paths. Until one day they started talking at the practice for their schoolâ€™s upcoming chorus festival. After school, the two meet regularly, as Hikaru helps Rihito to improve his singing skills. While they listen to each otherâ€™s voice and harmonize, their hearts start to beat together.',\n",
       "  'popularity': 12.309,\n",
       "  'poster_path': '/cIfRCA5wEvj9tApca4UDUagQEiM.jpg',\n",
       "  'release_date': '2016-02-20',\n",
       "  'title': 'Dou kyu sei â€“ Classmates',\n",
       "  'video': False,\n",
       "  'vote_average': 8.5,\n",
       "  'vote_count': 257},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/l6hQWH9eDksNJNiXWYRkWqikOdu.jpg',\n",
       "  'genre_ids': [14, 18, 80],\n",
       "  'id': 497,\n",
       "  'original_language': 'en',\n",
       "  'original_title': 'The Green Mile',\n",
       "  'overview': \"A supernatural tale set on death row in a Southern prison, where gentle giant John Coffey possesses the mysterious power to heal people's ailments. When the cell block's head guard, Paul Edgecomb, recognizes Coffey's miraculous gift, he tries desperately to help stave off the condemned man's execution.\",\n",
       "  'popularity': 85.372,\n",
       "  'poster_path': '/velWPhVMQeQKcxggNEU8YmIo52R.jpg',\n",
       "  'release_date': '1999-12-10',\n",
       "  'title': 'The Green Mile',\n",
       "  'video': False,\n",
       "  'vote_average': 8.5,\n",
       "  'vote_count': 14491},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/aQ7444JX7gefPhGJTlvilj3zG2S.jpg',\n",
       "  'genre_ids': [10402],\n",
       "  'id': 553512,\n",
       "  'original_language': 'ko',\n",
       "  'original_title': 'ë²ˆ ë” ìŠ¤í…Œì´ì§€: ë” ë¬´ë¹„',\n",
       "  'overview': 'A documentary following the worldwide famous music group BTS, as they tour the world and share their experience along with their beloved band friends and fans.',\n",
       "  'popularity': 18.278,\n",
       "  'poster_path': '/pJKy1yvnKh8UjcuYeG3Rt35xHFA.jpg',\n",
       "  'release_date': '2018-11-15',\n",
       "  'title': 'Burn the Stage: The Movie',\n",
       "  'video': False,\n",
       "  'vote_average': 8.5,\n",
       "  'vote_count': 367},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/w2uGvCpMtvRqZg6waC1hvLyZoJa.jpg',\n",
       "  'genre_ids': [10749],\n",
       "  'id': 696374,\n",
       "  'original_language': 'en',\n",
       "  'original_title': \"Gabriel's Inferno\",\n",
       "  'overview': \"An intriguing and sinful exploration of seduction, forbidden love, and redemption, Gabriel's Inferno is a captivating and wildly passionate tale of one man's escape from his own personal hell as he tries to earn the impossible--forgiveness and love. Watch Here : https://classic-blog.udn.com/mobile/aaef2970/177226755\",\n",
       "  'popularity': 12.563,\n",
       "  'poster_path': '/oyG9TL7FcRP4EZ9Vid6uKzwdndz.jpg',\n",
       "  'release_date': '2020-05-29',\n",
       "  'title': \"Gabriel's Inferno\",\n",
       "  'video': False,\n",
       "  'vote_average': 8.5,\n",
       "  'vote_count': 2289},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/v5CEt88iDsuoMaW1Q5Msu9UZdEt.jpg',\n",
       "  'genre_ids': [10749, 18],\n",
       "  'id': 730154,\n",
       "  'original_language': 'ja',\n",
       "  'original_title': 'ãã¿ã®çž³ãŒå•ã„ã‹ã‘ã¦ã„ã‚‹',\n",
       "  'overview': \"A tragic accident lead to Kaori's blindness, but she clings to life and the smaller pleasures it can still afford her. She meets Rui and begins to talk to him. Rui was once a promising kickboxer, but something happened in his past. Kaori's smile brings out a change in Rui. However, the two are connected in more than one way. Rui attempts to do what is right.\",\n",
       "  'popularity': 35.07,\n",
       "  'poster_path': '/cVn8E3Fxbi8HzYYtaSfsblYC4gl.jpg',\n",
       "  'release_date': '2020-10-23',\n",
       "  'title': 'Your Eyes Tell',\n",
       "  'video': False,\n",
       "  'vote_average': 8.5,\n",
       "  'vote_count': 356},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/nMKdUUepR0i5zn0y1T4CsSB5chy.jpg',\n",
       "  'genre_ids': [18, 28, 80, 53],\n",
       "  'id': 155,\n",
       "  'original_language': 'en',\n",
       "  'original_title': 'The Dark Knight',\n",
       "  'overview': 'Batman raises the stakes in his war on crime. With the help of Lt. Jim Gordon and District Attorney Harvey Dent, Batman sets out to dismantle the remaining criminal organizations that plague the streets. The partnership proves to be effective, but they soon find themselves prey to a reign of chaos unleashed by a rising criminal mastermind known to the terrified citizens of Gotham as the Joker.',\n",
       "  'popularity': 68.683,\n",
       "  'poster_path': '/qJ2tW6WMUDux911r6m7haRef0WH.jpg',\n",
       "  'release_date': '2008-07-14',\n",
       "  'title': 'The Dark Knight',\n",
       "  'video': False,\n",
       "  'vote_average': 8.5,\n",
       "  'vote_count': 28398},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/suaEOtk1N1sgg2MTM7oZd2cfVp3.jpg',\n",
       "  'genre_ids': [53, 80],\n",
       "  'id': 680,\n",
       "  'original_language': 'en',\n",
       "  'original_title': 'Pulp Fiction',\n",
       "  'overview': \"A burger-loving hit man, his philosophical partner, a drug-addled gangster's moll and a washed-up boxer converge in this sprawling, comedic crime caper. Their adventures unfurl in three stories that ingeniously trip back and forth in time.\",\n",
       "  'popularity': 61.157,\n",
       "  'poster_path': '/fIE3lAGcZDV1G6XM5KmuWnNsPp1.jpg',\n",
       "  'release_date': '1994-09-10',\n",
       "  'title': 'Pulp Fiction',\n",
       "  'video': False,\n",
       "  'vote_average': 8.5,\n",
       "  'vote_count': 23902},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/x4biAVdPVCghBlsVIzB6NmbghIz.jpg',\n",
       "  'genre_ids': [37],\n",
       "  'id': 429,\n",
       "  'original_language': 'it',\n",
       "  'original_title': 'Il buono, il brutto, il cattivo',\n",
       "  'overview': 'While the Civil War rages on between the Union and the Confederacy, three men â€“ a quiet loner, a ruthless hitman, and a Mexican bandit â€“ comb the American Southwest in search of a strongbox containing $200,000 in stolen gold.',\n",
       "  'popularity': 43.991,\n",
       "  'poster_path': '/bX2xnavhMYjWDoZp1VM6VnU1xwe.jpg',\n",
       "  'release_date': '1966-12-23',\n",
       "  'title': 'The Good, the Bad and the Ugly',\n",
       "  'video': False,\n",
       "  'vote_average': 8.5,\n",
       "  'vote_count': 6907},\n",
       " {'adult': False,\n",
       "  'backdrop_path': '/lXhgCODAbBXL5buk9yEmTpOoOgR.jpg',\n",
       "  'genre_ids': [12, 14, 28],\n",
       "  'id': 122,\n",
       "  'original_language': 'en',\n",
       "  'original_title': 'The Lord of the Rings: The Return of the King',\n",
       "  'overview': \"Aragorn is revealed as the heir to the ancient kings as he, Gandalf and the other members of the broken fellowship struggle to save Gondor from Sauron's forces. Meanwhile, Frodo and Sam take the ring closer to the heart of Mordor, the dark lord's realm.\",\n",
       "  'popularity': 151.92,\n",
       "  'poster_path': '/rCzpDGLbOoPwLjy3OAm5NUPOTrC.jpg',\n",
       "  'release_date': '2003-12-01',\n",
       "  'title': 'The Lord of the Rings: The Return of the King',\n",
       "  'video': False,\n",
       "  'vote_average': 8.5,\n",
       "  'vote_count': 20344}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44dd54d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
